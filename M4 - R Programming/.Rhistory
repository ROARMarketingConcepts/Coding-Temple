return(result)
}
predict_word <- function(bigPre,unigrs,bigrs,trigrs){
gamma2=0.7; gamma3=0.7  # initialize new discount rates
obs_trigs <- getObsTrigs(bigPre, trigrs)
unobs_trig_tails <- getUnobsTrigTails(obs_trigs$ngram, unigrs)
bo_bigrams <- getBOBigrams(bigPre, unobs_trig_tails)
# Separate bigrams into observed and unobserved using the appropriate equations
obs_bo_bigrams <- getObsBOBigrams(bigPre, unobs_trig_tails, bigrs)
unobs_bo_bigrams <- getUnobsBOBigrams(bigPre, unobs_trig_tails, obs_bo_bigrams)
# Calculate observed bigram probabilites
qbo_obs_bigrams <- getObsBigProbs(obs_bo_bigrams, unigrs, gamma2)
# Calculate alpha_big and unobserved bigram probabilities
unig <- str_split(bigPre, "_")[[1]][2]
unig <- unigrs[unigrs$ngram == unig,]
alpha_big <- getAlphaBigram(unig, bigrs, gamma2)
# Distribute discounted bigram probability mass to unobserved bigrams in   proportion to unigram ML
qbo_unobs_bigrams <- getQboUnobsBigrams(unobs_bo_bigrams, unigrs, alpha_big)
# Calculate observed trigram probabilities...
qbo_obs_trigrams <- getObsTriProbs(obs_trigs, bigrs, bigPre, gamma3)
# Finally, calculate unobserved trigram probabilities...
bigram <- bigrs[bigrs$ngram %in% bigPre, ]
alpha_trig <- getAlphaTrigram(obs_trigs, bigram, gamma3)
qbo_unobs_trigrams <- getUnobsTriProbs(bigPre, qbo_obs_bigrams,
qbo_unobs_bigrams, alpha_trig)
qbo_trigrams <- rbind(qbo_obs_trigrams, qbo_unobs_trigrams)
qbo_trigrams <- qbo_trigrams[order(-qbo_trigrams$prob), ]
# getPredictionMsg(qbo_trigrams)
return(qbo_trigrams)
}
bigPre = "bouquet_case"
word_list <- predict_word(bigPre,unigrs,bigrs,trigrs)
# word_list[grepl("bouquet_case_beer", ngram, fixed=TRUE)]
word_list[((word_list$ngram=="bouquet_case_beer") | (word_list$ngram=="bouquet_case_pretzels") | (word_list$ngram=="bouquet_case_cheese")| (word_list$ngram=="bouquet_case_soda")),]
bigPre = "would_mean"
word_list <- predict_word(bigPre,unigrs,bigrs,trigrs)
word_list[((word_list$ngram=="would_mean_world") | (word_list$ngram=="would_mean_best") | (word_list$ngram=="would_mean_most")| (word_list$ngram=="would_mean_universe")),]
bigPre = "make_me"
word_list <- predict_word(bigPre,unigrs,bigrs,trigrs)
word_list[((word_list$ngram=="make_me_bluest") | (word_list$ngram=="make_me_smelliest") | (word_list$ngram=="make_me_saddest")| (word_list$ngram=="make_me_happiest")),]
install.packages("rnn")
?rnn
??rnn
run.rnn_demo
library(rnn)
run.rnn_demo
install.packages("keras")
install.packages("tensorflow")
shiny::runApp('Desktop/Data Science with R/Capstone Project/Week 5/Week 5 Assignment')
runApp('Desktop/Data Science with R/Capstone Project/Week 5/Week 5 Assignment')
runApp('Desktop/Data Science with R/Capstone Project/Week 5/Week 5 Assignment')
runApp('Desktop/Data Science with R/Capstone Project/Week 5/Week 5 Assignment')
runApp('Desktop/Data Science with R/Capstone Project/Week 5/Week 5 Assignment')
# Load the raw data files.
# These lines of code will take a little time to execute, so please be patient!
NEI <- readRDS("exdata-data-NEI_data/summarySCC_PM25.rds")
SCC <- readRDS("exdata-data-NEI_data/Source_Classification_Code.rds")
merged_df <- merge(NEI,SCC,by="SCC")
total_emissions <- aggregate(NEI$Emission, by=list(NEI$year), sum)
plot(total_emissions,pch=16,xlab="Year",ylab="Emissions (tons)",main="Total Emissions by Year")
lines(total_emissions$Group.1,total_emissions$x)
grid(lty="dotted")
echo = TRUE
# First, we run the following line of code to clean up the memory from any previous R sessions.
rm(list=ls(all=TRUE))
# Load the raw dataset
df <- read.csv("repdata-data-StormData.csv")
echo = TRUE
# Let's look at a few rows of the df...
head(df)
echo = TRUE
library(dplyr)
# Add numbers in 'FATALITIES' and 'INJURIES' columns
df$CASUALTIES <- df$FATALITIES+df$INJURIES
# Let's sort the df by 'CASUALTIES' descending
df <- df %>% arrange(-CASUALTIES)
echo = TRUE
# Aggregate the casualties by event type
casualties_per_event <- aggregate(df$CASUALTIES, by=list(df$EVTYPE), sum)
names(casualties_per_event) <- c("EVTYPE", "TOTAL_CASUALTIES")
casualties_per_event <- casualties_per_event %>% arrange(-TOTAL_CASUALTIES)
# Filter for events where the total casualties is greater than 1000
casualties_per_event <- casualties_per_event[casualties_per_event$TOTAL_CASUALTIES >= 1000,]
# Plot a column chart of Total Casualties vs. Event Type
library(ggplot2)
library(scales)
# png("total_casualties_by_event_type.png")
ggplot(data=casualties_per_event, aes(x = reorder(EVTYPE, -TOTAL_CASUALTIES), y = TOTAL_CASUALTIES)) + geom_bar(position="dodge",stat="identity",color="blue") + xlab("Event Type") + ylab("Number of Casualities") + theme(axis.text.x = element_text(angle = 270,size=15,vjust=0.5,color="blue"), axis.text.y = element_text(size=15,color="blue"),plot.title = element_text(size = 25, face = "bold",hjust=0.5),axis.title = element_text(size=15,face="bold")) + ggtitle("Total Casualties by Event Type") + geom_text(aes(label=TOTAL_CASUALTIES), position=position_dodge(width=0.5), size=5, vjust=-2)+scale_y_continuous(label=comma)
# dev.off()
echo = TRUE
# First, we run the following line of code to clean up the memory from any previous R sessions.
rm(list=ls(all=TRUE))
# Load the raw dataset
df <- read.csv("repdata-data-StormData.csv")
echo = TRUE
# Let's look at a few rows of the df...
head(df)
echo = TRUE
library(dplyr)
# Add numbers in 'FATALITIES' and 'INJURIES' columns
df$CASUALTIES <- df$FATALITIES+df$INJURIES
# Let's sort the df by 'CASUALTIES' descending
df <- df %>% arrange(-CASUALTIES)
echo = TRUE
# Aggregate the casualties by event type
casualties_per_event <- aggregate(df$CASUALTIES, by=list(df$EVTYPE), sum)
names(casualties_per_event) <- c("EVTYPE", "TOTAL_CASUALTIES")
casualties_per_event <- casualties_per_event %>% arrange(-TOTAL_CASUALTIES)
# Filter for events where the total casualties is greater than 1000
casualties_per_event <- casualties_per_event[casualties_per_event$TOTAL_CASUALTIES >= 1000,]
# Plot a column chart of Total Casualties vs. Event Type
library(ggplot2)
library(scales)
# png("total_casualties_by_event_type.png")
ggplot(data=casualties_per_event, aes(x = reorder(EVTYPE, -TOTAL_CASUALTIES), y = TOTAL_CASUALTIES)) + geom_bar(position="dodge",stat="identity",color="blue") + xlab("Event Type") + ylab("Number of Casualities") + theme(axis.text.x = element_text(angle = 270,size=15,vjust=0.5,color="blue"), axis.text.y = element_text(size=15,color="blue"),plot.title = element_text(size = 25, face = "bold",hjust=0.5),axis.title = element_text(size=15,face="bold")) + ggtitle("Total Casualties by Event Type") + geom_text(aes(label=TOTAL_CASUALTIES), position=position_dodge(width=0.5), size=5, vjust=-2)+scale_y_continuous(label=comma)
# dev.off()
plot(cars)
library(lubridate)
library(tidyverse)
knitr::opts_chunk$set(echo = TRUE)
library(chron)
# Read in the data file.
df <- read.csv("activity.csv")
# Convert 'date' column to datetime variable.
df$date <- as.Date(df$date,format="%Y-%m-%d")
# Convert 'interval' to a time variable
# df$interval <- times(sub("(.{2})", "\\1:", sprintf("%04d:00", df$interval)))
knitr::opts_chunk$set(echo = TRUE)
library(chron)
# Read in the data file.
df <- read.csv("activity.csv")
# Convert 'date' column to datetime variable.
df$date <- as.Date(df$date,format="%Y-%m-%d")
# Convert 'interval' to a time variable
# df$interval <- times(sub("(.{2})", "\\1:", sprintf("%04d:00", df$interval)))
# Drop rows with NA in 'steps' column
df1 <- df[complete.cases(df),]
# Calculate total steps per day
total_steps_per_day <- aggregate(df1$steps, by=list(df1$date), sum)
# Generate histogram
# png("Histogram of Total Steps Per Day.png")
hist(total_steps_per_day$x,breaks=20,col="blue",xlab="Total Steps Per Day",main="Histogram of Total Steps Per Day")
# dev.off()
# Calculate and report the mean and median of the total number of steps taken per day
mean <- mean(total_steps_per_day$x)
median <- median(total_steps_per_day$x)
paste0("Mean Total Steps per Day: ",round(mean,2))
paste0("Median Total Steps per Day: ",round(median,2))
library(ggplot2)
# Calculate mean number of steps for each time period
mean_steps <- aggregate(df1$steps, by=list(df1$interval), mean)
names(mean_steps) <- c("time","steps")
# Plot the line graph
# png("Mean Number of Steps by Time of Day.png")
ggplot(data=mean_steps, aes(x = time, y = steps))+geom_line()+xlab("Time of Day (HHMM)")+ggtitle("Mean Number of Steps by Time of Day")
# dev.off()
# Determine time interval when mean number of steps is maximum
mean_steps[which.max(mean_steps$steps), ]$time
# Calculate the number of rows with NAs
sum(!complete.cases(df))
library(plyr)
library(dplyr)
# Get rows in df where NAs are present
na_rows <- df[!complete.cases(df),]
# Rename columns
names(na_rows) <- c("steps","date","time")
# Impute mean number of steps for each time interval
na_rows <- merge(na_rows,mean_steps, by=c("time"))
# 'df1' is the original dataset with the NA rows deleted. We need to combine 'na_rows' with 'df1'. However, we need to clean up 'na_rows' a bit...
na_rows = subset(na_rows, select = -c(steps.x) )
names(na_rows) <- c("interval","date","steps")
# Combine 'df1' and 'na_rows'
df1 <- union(df1,na_rows)
# Sort 'df1' by date and then by interval
df1 <- df1 %>% arrange(date, interval)
# Calculate total steps per day
total_steps_per_day <- aggregate(df1$steps, by=list(df1$date), sum)
# Generate histogram
# png("Histogram of Total Steps Per Day with Imputed Values.png")
hist(total_steps_per_day$x,breaks=20,col="blue",xlab="Total Steps Per Day",main="Histogram of Total Steps Per Day")
# dev.off()
# Calculate and report the mean and median of the total number of steps taken per day
mean <- mean(total_steps_per_day$x)
median <- median(total_steps_per_day$x)
paste0("Mean Total Steps per Day: ",round(mean,2))
paste0("Median Total Steps per Day: ",round(median,2))
# Determine day of week for each date
df1$day <- weekdays(df1$date)
# Recode day of week to 'Weekday' or 'Weekend'
df1$weekday_or_weekend[df1$day %in% c("Monday","Tuesday","Wednesday","Thursday","Friday")] <- "Weekday"
df1$weekday_or_weekend[df1$day %in% c("Saturday","Sunday")] <- "Weekend"
# Calculate mean number of steps for each time interval on Weekdays and Weekends
mean_steps <- aggregate(df1$steps, by=list(df1$weekday_or_weekend,df1$interval), mean)
names(mean_steps) <- c("Weekday_Weekend","time","steps")
# Sort 'mean_steps' by weekday/weekend and then by time
mean_steps <- mean_steps %>% arrange(Weekday_Weekend, time)
# The 'Weekday_Weekend' column must be converted to a factor variable for plotting
mean_steps$Weekday_Weekend <- as.factor(mean_steps$Weekday_Weekend)
# Create plots
# png("Mean Number of Steps by Time of Day Weekday Weekend.png")
ggplot(mean_steps, aes(x=time, y=steps))+geom_line()+facet_wrap(~Weekday_Weekend,nrow=2)+xlab("Time of Day")+ylab("Mean steps")+ggtitle("Mean Number of Steps by Time of Day")
# dev.off()
View(bigrs)
View(word_list)
demo()
knitr::opts_chunk$set(echo = TRUE)
# eCornell Hex Codes:
crimson = '#b31b1b' #Crimson
lightGray = '#cecece' #lightGray
darkGray = '#606366'
skyBlue = '#92b2c4' #skyblue
gold = '#fbb040' #gold
ecBlack = '#393f47' #ecBlack
# Load the data.
school = read.csv('mrc_table2.csv', header = TRUE, check.names = FALSE)
school = school[,names(school) %in%
c('name', 'type', 'tier', 'tier_name', 'mr_kq5_pq1',
'par_median', 'k_median')]
names(school)[5:7] <- c("mobility_rate", "parent_income", "student_income")
## Calculate the mean parent income for students at highly selective private schools:
school = school[school$tier_name %in% c("Highly selective private", "Highly selective public"),]
par.income.prv = school$parent_income[school$tier_name == 'Highly selective private']
mean(par.income.prv)
## Calculate the mean parent income for students at highly selective public schools.
par.income.pub = school$parent_income[school$tier_name == 'Highly selective public']
mean(par.income.pub)
# Create the boxplot:
boxplot(par.income.prv, par.income.pub, names = c('Highly selective private', 'Highly selective public'), ylab = 'Parent Income (USD)',
main = 'Parent Income: HS private and public schools', col = ecBlack)
# Create a permutation distribution:
set.seed(1)
P = 10000
store_mean_diff = rep(0, P)
for (n in 1:P){
school.perm = school
school.perm$parent_income = sample(school.perm$parent_income, replace = FALSE)
school.perm.prv = school.perm$parent_income[school.perm$tier_name == 'Highly selective private']
school.perm.pub = school.perm$parent_income[school.perm$tier_name == 'Highly selective public']
store_mean_diff[n] = mean(school.perm.prv) - mean(school.perm.pub)
}
# Plot the observed sample statistic on the histogram:
hist(store_mean_diff, breaks = 20, freq = FALSE, col = ecBlack, border = 'white',
xlab = 'Mean Diff of Parent Income',
main = 'Histogram of Parent Income Diff (Permuted Data)')
install.packages('tidyverse')
library(tidyverse)
library(tidyverse)
install.packages("tidyverse")
library("tidyverse")
install.packages("tidyverse")
help()
install.packages(c("nycflights13", "gapminder", "Lahman"))
myplot <- mpg
mpg
mpg
# install.packages("tidyverse")
library("tidyverse")
help()
install.packages(c("nycflights13", "gapminder", "Lahman"))
myplot <- load(mpg)
myplot <- load('mpg')
str(mpg)
myplot = mpg
View(myplot)
View(myplot)
myplot <- mpg
# Load the datasets package (usually not necessary as it's loaded by default)
library(datasets)
# Import the mtcars dataset
data(CO2)
# Display the first few rows of the dataset
head(CO2)
# Load the datasets package (usually not necessary as it's loaded by default)
library(datasets)
# Import the CO2 dataset
data(CO2)
# Display the first few rows of the dataset
head(CO2)
# Get a set of summary stats for the dataset
summary(CO2)
View(CO2)
# Create a histogram
hist(CO2,
main="Histogram of Random Numbers",
xlab="Value",
ylab="Frequency",
col="blue",
border="black")
# Create a histogram
hist(CO2$conc,
main="Histogram of Random Numbers",
xlab="Value",
ylab="Frequency",
col="blue",
border="black")
# Create a histogram
hist(CO2$conc,
main="Histogram of CO2$conc",
xlab="Value",
ylab="Frequency",
col="blue",
border="black")
# Create a histogram
hist(CO2$conc,
main="Histogram of CO2$conc",
xlab="conc Value",
ylab="Frequency",
col="blue",
border="black")
# Create a histogram
hist(CO2$uptake,
main="Histogram of CO2$uptake",
xlab="conc Value",
ylab="Frequency",
col="blue",
border="black")
head(CO2)
summary(CO2)
library(tidyverse)
CO2
head(CO2)
summary(CO2)
ggplot(CO2, aes(x=Treatment, y=uptake, fill=Treatment)) +
geom_col() +
labs(title = "Uptake of C02 by Treatment",
x = "Treatment",
y = "Uptake Of CO2") +
theme_classic()
#2. Uptake of C02 by Type:
ggplot(CO2, aes(x=Type, y=uptake, fill=Type)) +
geom_col() +
labs(title = "Uptake of CO2 by Type")
#3. Box plot analysis by Type:
ggplot(CO2, aes(x=uptake, y=Type)) +
geom_boxplot()
plant_group <- group_by(CO2, Plant) %>%
summarize(avg_uptake = mean(uptake))
ggplot(plant_group, aes(x=Plant, y=avg_uptake)) +
geom_line(group = 1) +
geom_point() +
labs(title = "Average Uptake of CO2 by Plant",
x = "Plant",
y = "Average Uptake")
co2_uptake <- select(CO2, uptake)
co2_conc <- select(CO2, conc)
correlation_result <- cor(co2_conc, co2_uptake)
print(correlation_result)
# Load the datasets package (usually not necessary as it's loaded by default)
library(datasets)
library(ggplot2)
# Import the CO2 dataset
data(mtcars)
# Display the first few rows of the dataset
head(mtcars)
# Get a set of summary stats for the dataset
summary(mtcars)
# Create a histogram
ggplot(mtcars, aes(x=mpg)) +
geom_histogram(color = "black", fill = "steelblue", binwidth = 1) +
labs(x = "MPG", y = "Frequency") +
ggtitle("Histogram of MPG") +
theme_minimal()
# Create a histogram
ggplot(mtcars, aes(x=wt)) +
geom_histogram(color = "black", fill = "steelblue", binwidth = 0.1) +
labs(x = "Weight", y = "Frequency") +
ggtitle("Histogram of Weight") +
theme_minimal()
ggplot(mtcars, aes(x = factor(cyl))) +
geom_bar(color = "black", fill = "steelblue") +
labs(title = "Frequency of Number of Cylinders", x = "Number of Cylinders", y = "Count") + theme_minimal()
ggplot(mtcars, aes(x = factor(gear))) +
geom_bar(color = "black", fill = "steelblue") +
labs(title = "Frequency of Gear Type", x = "Gear Type", y = "Count") + theme_minimal()
# Load the datasets package (usually not necessary as it's loaded by default)
library(datasets)
library(ggplot2)
# Import the CO2 dataset
data(mtcars)
# Display the first few rows of the dataset
head(mtcars)
# Get a set of summary stats for the dataset
summary(mtcars)
positive <- c("21", "22", "33", "21", "27") ##Percentage
negative<- c("71", "77", "67", "79", "73")  ##Precentage
sample <- c("Hr", "Fi", "We", "Pa", "Ki")
mydata <- data.frame(positive , negative, sample)
mydata
mydata %>% pivot_longer(cols = !sample, names_to = "status", values_to = "percentage") %>%
ggplot(aes(fill = status, x = sample, y = percentage)) +
geom_bar(position = "stack", stat = "identity")
mydata %>% pivot_longer(cols = !sample, names_to = "status", values_to = ="percentage") %>%
mydata %>% pivot_longer(cols = !sample, names_to = "status", values_to ="percentage") %>%
ggplot(aes(fill = status, x = sample, y = percentage)) +
geom_bar(position = "stack", stat = "identity")
library(tidyverse)
mydata %>% pivot_longer(cols = !sample, names_to = "status", values_to ="percentage") %>%
ggplot(aes(fill = status, x = sample, y = percentage)) +
geom_bar(position = "stack", stat = "identity")
library(datasets)
library(ggplot2)
data(mtcars)
library(datasets)
library(ggplot2)
data(mtcars)
head(mtcars)
ggplot(mtcars, aes(x = cyl,fill = vs )) +
geom_bar()
ggplot(mtcars, aes(x = cyl,fill = gear )) +
geom_bar()
ggplot(mtcars, aes(x = factor(cyl),fill = gear )) +
geom_bar()
ggplot(mtcars, aes(x = factor(cyl),fill = factor(gear)) +
geom_bar()
ggplot(mtcars, aes(x = factor(cyl),fill = factor(gear))) +
geom_bar()
ggplot(mtcars, aes(x = factor(cyl),fill = factor(gear))) +
geom_bar() +
labs(x = "Number of Cylinders")
ggplot(mtcars, aes(x = factor(cyl),fill = factor(gear))) +
geom_bar() +
labs(x = "Number of Cylinders", fill = "Number of Gears")
my_vector <- c(1,3,5,7,9)
print(my_vector)
my_vector [3]
my_vector `<- c(1,3,5,7,9)
my_vector [2] * 2
my_vector `<- c(1,3,5,7,9)
my_vector <- c(1,3,5,7,9)
my_vector <- my_vector [2] * 2
my_vector
my_list <- list(vector = c(10,20,30), country c("USA", "England", "Japan"),
my_list <- list(vector = c(10,20,30), country = c("USA", "England", "Japan"),
city =  data.frame c("Philadelphia", "London","Tokyo"),
# Victor:
# 1. create a numeric vector named my_victor
my_vector <- c(1,3,5,7,9)
# 2. Extract the third element from my_vector
third_element_extract <- my_victor[3]
# Victor:
# 1. create a numeric vector named my_victor
my_vector <- c(1,3,5,7,9)
# 2. Extract the third element from my_vector
third_element_extract <- my_vector[3]
# 3. Updating second element twice origianl value
my_vector_twice <- my_vector[2] * 2
student_data <- data.frame(Student_ID = c(1:5), Name = c("Bob","John","Gus","Willy","lilly"), Score = c(87,90,91,62,98))
student_data
student_data$Score[3] <- 95
student_data
my_list <- list(
c(10, 20, 30),
c("USA", "Englend", "Norway"),
data.frame(
City = c("New York", "London", "Oslo"),
Population = c(3429000, 2030000, 500000)
)
)
my_list
# Access and print the second element of the character vector within my_list
second_country <- my_list[[2]][2]
print(second_country)
library("dplyr")
mtcars
select(mtcars,cyl,disp,hp,drat)
high_hp_cars <- data.frame(filter(mtcars, hp > 150))
df
View(myplot)
View(myplot)
library(datasets)
df <- data("CO2")
df
library(datasets)
data("CO2")
force(CO2)
View(CO2)
library(ggplot2)
library(dplyr)
data(mtcars)
str(mtcars)
summary(mtcars)
mtcars <- mtcars %>%
rownames_to_column(var = "car_name")
library(ggplot2)
library(dplyr)
data(mtcars)
str(mtcars)
summary(mtcars)
mtcars <- mtcars %>%
rownames_to_column(var = "car_name")
library(ggplot2)
library(dplyr)
data(mtcars)
str(mtcars)
summary(mtcars)
mtcars <- mtcars %>%
add_rownames(var = "car_name")
library(ggplot2)
library(dplyr)
data(mtcars)
str(mtcars)
summary(mtcars)
mtcars <- mtcars %>%
rownames_to_column(var = "car_name")
install.packages('coro')
library(coro)
setwd("~/Desktop/Machine Learning and Data Analysis/Coding Temple/4 - R Programming")
df <- read.csv('female-mice-weights.csv')
df
df <- read.csv('female-mice-weights.csv')
df
View(df)
